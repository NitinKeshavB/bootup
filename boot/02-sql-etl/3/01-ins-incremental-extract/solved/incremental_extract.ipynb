{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from secrets_config import source_db_user, source_db_password, source_db_server_name, source_db_database_name\n",
    "import jinja2 as j2 \n",
    "\n",
    "# import libraries for sql \n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to database \n",
    "source_connection_url = URL.create(\n",
    "    drivername = \"postgresql+pg8000\", \n",
    "    username = source_db_user,\n",
    "    password = source_db_password,\n",
    "    host = source_db_server_name, \n",
    "    port = 5432,\n",
    "    database = source_db_database_name, \n",
    ")\n",
    "\n",
    "source_engine = create_engine(source_connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import logging \n",
    "import datetime as dt \n",
    "import numpy as np\n",
    "\n",
    "def get_incremental_value(table_name, path=\"extract_log\"):\n",
    "    df = pd.read_csv(f\"{path}/{table_name}.csv\")\n",
    "    return df[df[\"log_date\"] == df[\"log_date\"].max()][\"incremental_value\"].values[0]\n",
    "\n",
    "def upsert_incremental_log(log_path, table_name, incremental_value)->bool:\n",
    "    if f\"{table_name}.csv\" in os.listdir(log_path):\n",
    "        df_existing_incremental_log = pd.read_csv(f\"{log_path}/{table_name}.csv\")\n",
    "        df_incremental_log = pd.DataFrame(data={\n",
    "            \"log_date\": [dt.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")], \n",
    "            \"incremental_value\": [incremental_value]\n",
    "        })\n",
    "        df_updated_incremental_log = pd.concat([df_existing_incremental_log,df_incremental_log])\n",
    "        df_updated_incremental_log.to_csv(f\"{log_path}/{table_name}.csv\", index=False)\n",
    "    else: \n",
    "        df_incremental_log = pd.DataFrame(data={\n",
    "            \"log_date\": [dt.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")], \n",
    "            \"incremental_value\": [incremental_value]\n",
    "        })\n",
    "        df_incremental_log.to_csv(f\"{log_path}/{table_name}.csv\", index=False)\n",
    "    return True \n",
    "\n",
    "def extract_from_database(table_name, engine, path=\"extract_queries\")->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Builds models with a matching file name in the models_path folder. \n",
    "    - `table_name`: the name of the table (without .sql)\n",
    "    - `path`: the path to the extract queries directory containing the sql files. defaults to `extract_queries`\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format=\"[%(levelname)s][%(asctime)s]: %(message)s\")\n",
    "    \n",
    "    logging.info(f\"Extracting table: {table_name}\")\n",
    "    if f\"{table_name}.sql\" in os.listdir(path):\n",
    "        # read sql contents into a variable \n",
    "        with open(f\"{path}/{table_name}.sql\") as f: \n",
    "            raw_sql = f.read()\n",
    "        \n",
    "        # get config \n",
    "        config = j2.Template(raw_sql).make_module().config \n",
    "        \n",
    "        if config[\"extract_type\"].lower() == \"incremental\": \n",
    "            incremental_path = \"extract_log\"\n",
    "            if not os.path.exists(incremental_path): \n",
    "                os.mkdir(incremental_path)\n",
    "            if f\"{table_name}.csv\" in os.listdir(incremental_path):\n",
    "                # get incremental value and perform incremental extract \n",
    "                current_max_incremental_value = get_incremental_value(table_name, path=incremental_path)\n",
    "                parsed_sql = j2.Template(raw_sql).render(source_table = table_name, engine=engine, is_incremental=True, incremental_value=current_max_incremental_value)\n",
    "                # execute incremental extract\n",
    "                df = pd.read_sql(sql=parsed_sql, con=engine)\n",
    "                # update max incremental value \n",
    "                if len(df) > 0: \n",
    "                    max_incremental_value = df[config[\"incremental_column\"]].max()\n",
    "                else: \n",
    "                    max_incremental_value = current_max_incremental_value\n",
    "                upsert_incremental_log(log_path=incremental_path, table_name=table_name, incremental_value=max_incremental_value)\n",
    "                logging.info(f\"Successfully extracted table: {table_name}, rows extracted: {len(df)}\")\n",
    "                return df \n",
    "            else: \n",
    "                # parse sql using jinja \n",
    "                parsed_sql = j2.Template(raw_sql).render(source_table = table_name, engine=engine)\n",
    "                # perform full extract \n",
    "                df = pd.read_sql(sql=parsed_sql, con=engine)\n",
    "                # store latest incremental value \n",
    "                max_incremental_value = df[config[\"incremental_column\"]].max()\n",
    "                upsert_incremental_log(log_path=incremental_path, table_name=table_name, incremental_value=max_incremental_value)\n",
    "                logging.info(f\"Successfully extracted table: {table_name}, rows extracted: {len(df)}\")\n",
    "                return df \n",
    "        else: \n",
    "            # parse sql using jinja \n",
    "            parsed_sql = j2.Template(raw_sql).render(source_table = table_name, engine=engine)\n",
    "            # perform full extract \n",
    "            df = pd.read_sql(sql=parsed_sql, con=engine)\n",
    "            logging.info(f\"Successfully extracted table: {table_name}, rows extracted: {len(df)}\")\n",
    "            return df \n",
    "    else: \n",
    "        logging.error(f\"Could not find table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022-07-24 16:46:57,170]: Extracting table: orders\n",
      "[INFO][2022-07-24 16:46:57,996]: Successfully extracted table: orders, rows extracted: 12003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderid</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>customerid</th>\n",
       "      <th>netamount</th>\n",
       "      <th>tax</th>\n",
       "      <th>totalamount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2004-01-27</td>\n",
       "      <td>7888</td>\n",
       "      <td>313.24</td>\n",
       "      <td>25.84</td>\n",
       "      <td>339.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>4858</td>\n",
       "      <td>54.90</td>\n",
       "      <td>4.53</td>\n",
       "      <td>59.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2004-01-17</td>\n",
       "      <td>15399</td>\n",
       "      <td>160.10</td>\n",
       "      <td>13.21</td>\n",
       "      <td>173.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2004-01-28</td>\n",
       "      <td>17019</td>\n",
       "      <td>106.67</td>\n",
       "      <td>8.80</td>\n",
       "      <td>115.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004-01-09</td>\n",
       "      <td>14771</td>\n",
       "      <td>256.00</td>\n",
       "      <td>21.12</td>\n",
       "      <td>277.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>11999</td>\n",
       "      <td>2004-12-25</td>\n",
       "      <td>1485</td>\n",
       "      <td>175.34</td>\n",
       "      <td>14.47</td>\n",
       "      <td>189.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>12000</td>\n",
       "      <td>2004-12-15</td>\n",
       "      <td>7393</td>\n",
       "      <td>205.09</td>\n",
       "      <td>16.92</td>\n",
       "      <td>222.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>12001</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>10205</td>\n",
       "      <td>50.10</td>\n",
       "      <td>5.02</td>\n",
       "      <td>55.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001</th>\n",
       "      <td>12002</td>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>10205</td>\n",
       "      <td>50.10</td>\n",
       "      <td>5.02</td>\n",
       "      <td>55.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>12003</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>10205</td>\n",
       "      <td>50.10</td>\n",
       "      <td>5.02</td>\n",
       "      <td>55.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12003 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       orderid   orderdate  customerid  netamount    tax  totalamount\n",
       "0            1  2004-01-27        7888     313.24  25.84       339.08\n",
       "1            2  2004-01-01        4858      54.90   4.53        59.43\n",
       "2            3  2004-01-17       15399     160.10  13.21       173.31\n",
       "3            4  2004-01-28       17019     106.67   8.80       115.47\n",
       "4            5  2004-01-09       14771     256.00  21.12       277.12\n",
       "...        ...         ...         ...        ...    ...          ...\n",
       "11998    11999  2004-12-25        1485     175.34  14.47       189.81\n",
       "11999    12000  2004-12-15        7393     205.09  16.92       222.01\n",
       "12000    12001  2005-01-01       10205      50.10   5.02        55.12\n",
       "12001    12002  2005-01-02       10205      50.10   5.02        55.12\n",
       "12002    12003  2005-01-03       10205      50.10   5.02        55.12\n",
       "\n",
       "[12003 rows x 6 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_from_database(table_name=\"orders\", engine=source_engine, path=\"extract_queries\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orderid          int64\n",
       "orderdate       object\n",
       "customerid       int64\n",
       "netamount      float64\n",
       "tax            float64\n",
       "totalamount    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2004-01-27\n",
       "1        2004-01-01\n",
       "2        2004-01-17\n",
       "3        2004-01-28\n",
       "4        2004-01-09\n",
       "            ...    \n",
       "11998    2004-12-25\n",
       "11999    2004-12-15\n",
       "12000    2005-01-01\n",
       "12001    2005-01-02\n",
       "12002    2005-01-03\n",
       "Name: orderdate, Length: 12003, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"orderdate\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec7476cd5298a73f69e8eecc398cdeac6e308767034e2d84faebe029453106ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from secrets_config import source_db_user, source_db_password, source_db_server_name, source_db_database_name\n",
    "import jinja2 as j2 \n",
    "\n",
    "# import libraries for sql \n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to the source database \n",
    "source_connection_url = URL.create(\n",
    "    drivername = \"postgresql+pg8000\", \n",
    "    username = source_db_user,\n",
    "    password = source_db_password,\n",
    "    host = source_db_server_name, \n",
    "    port = 5432,\n",
    "    database = source_db_database_name, \n",
    ")\n",
    "\n",
    "source_engine = create_engine(source_connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import logging \n",
    "\n",
    "# create function to extract data from a source database table using a `select` query from a SQL file \n",
    "def extract_from_database(table_name, engine, path=\"extract_queries\")->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts data from a table using a SQL query specified in a SQL File \n",
    "    - `table_name`: the name of the table (without .sql)\n",
    "    - `path`: the path to the extract queries directory containing the sql files. defaults to `extract_queries`\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format=\"[%(levelname)s][%(asctime)s]: %(message)s\")\n",
    "    \n",
    "    if f\"{table_name}.sql\" in os.listdir(path):\n",
    "        logging.info(f\"Extracting table: {table_name}\")\n",
    "    \n",
    "        # read sql contents into a variable \n",
    "        with open(f\"{path}/{table_name}.sql\") as f: \n",
    "            raw_sql = f.read()\n",
    "\n",
    "        # parse sql using jinja \n",
    "        parsed_sql = j2.Template(raw_sql).render(source_table = table_name, engine=engine)\n",
    "        # # execute parsed sql \n",
    "        df = pd.read_sql(sql=parsed_sql, con=engine)\n",
    "\n",
    "        logging.info(f\"Successfully extracted table: {table_name}, rows extracted: {len(df)}\")\n",
    "        return df \n",
    "    else: \n",
    "        logging.error(f\"Could not find table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite data to the target database \n",
    "def upsert_to_database(df: pd.DataFrame, table_name: str, engine)->bool: \n",
    "    \"\"\"\n",
    "    Upsert dataframe to a database table \n",
    "    - `df`: pandas dataframe \n",
    "    - `table`: name of the target table \n",
    "    - `engine`: connection engine to database \n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO, format=\"[%(levelname)s][%(asctime)s]: %(message)s\")\n",
    "    logging.info(f\"Writing to table: {table_name}\")\n",
    "    df.to_sql(name=table_name, con=engine, if_exists=\"replace\", index=False)\n",
    "    logging.info(f\"Successful write to table: {table_name}, rows inserted/updated: {len(df)}\")\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets_config import target_db_user, target_db_password, target_db_server_name, target_db_database_name\n",
    "# create connection to the target database \n",
    "target_connection_url = URL.create(\n",
    "    drivername = \"postgresql+pg8000\", \n",
    "    username = target_db_user,\n",
    "    password = target_db_password,\n",
    "    host = target_db_server_name, \n",
    "    port = 5432,\n",
    "    database = target_db_database_name, \n",
    ")\n",
    "\n",
    "target_engine = create_engine(target_connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an extract and load pipeline \n",
    "def extract_load_pipeline(source_engine, target_engine, path=\"extract_queries\"): \n",
    "    for file in os.listdir(path):\n",
    "        table_name = file.replace(\".sql\", \"\")\n",
    "        df = extract_from_database(table_name=table_name, engine=source_engine, path=path)\n",
    "        upsert_to_database(df=df, table_name=table_name, engine=target_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022-07-26 21:07:14,963]: Extracting table: rental\n",
      "[INFO][2022-07-26 21:07:15,648]: Successfully extracted table: rental, rows extracted: 16044\n",
      "[INFO][2022-07-26 21:07:15,649]: Writing to table: rental\n",
      "[INFO][2022-07-26 21:07:23,792]: Successful write to table: rental, rows inserted/updated: 16044\n"
     ]
    }
   ],
   "source": [
    "# run the extract and load pipeline for sql files that are found \n",
    "extract_load_pipeline(\n",
    "    source_engine=source_engine, \n",
    "    target_engine=target_engine, \n",
    "    path=\"extract_queries\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec7476cd5298a73f69e8eecc398cdeac6e308767034e2d84faebe029453106ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
